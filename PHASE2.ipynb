{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkFf2qOLGvu0"
   },
   "outputs": [],
   "source": [
    "# python -m visdom.server (터미널에 실행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1nBDv3HGvu2"
   },
   "outputs": [],
   "source": [
    "# %reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIrA2YbfGvu3"
   },
   "outputs": [],
   "source": [
    "############ HYPER PARAMETER SETTING ############\n",
    "\n",
    "# ML_model='CNN'\n",
    "# ML_model='NN'\n",
    "ML_model='Linear'\n",
    "\n",
    "batch_size = 200\n",
    "num_train_images = batch_size*165\n",
    "learning_rate = 0.001\n",
    "how_many_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6Z-9-81Gvu3"
   },
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RSg_NJFGvu4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import random\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9SdCnhqGvu4"
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ism_PAxPGvu4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRyzd6hMGvu5",
    "outputId": "7c43c44b-83ca-4aad-aeee-2d99aa4d0e7f"
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffZqF520Gvu6"
   },
   "outputs": [],
   "source": [
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "    '''num, loss_value, are Tensor'''\n",
    "    vis.line(X=num,\n",
    "             Y=loss_value,\n",
    "             win = loss_plot,\n",
    "             update='append'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjkhXXDWGvu7"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHJW_M4QGvu7"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('paths_data.xlsx', sheet_name='Sheet1')\n",
    "df_np=df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUtNs3wqGvu7"
   },
   "outputs": [],
   "source": [
    "how_many_images=df_np.shape[0]\n",
    "num_test_images=how_many_images-num_train_images\n",
    "last_column_index=df_np.shape[1]-1\n",
    "\n",
    "number_of_points=last_column_index-1\n",
    "\n",
    "Label_total=df_np[:,last_column_index]\n",
    "\n",
    "paths=df_np[:,:-2].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDle0G3bGvu7",
    "outputId": "9a18ac1d-70f2-4253-bf6d-7d5953113a87"
   },
   "outputs": [],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOLqrL-TGvu8"
   },
   "outputs": [],
   "source": [
    "sorted_first_path=np.sort(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85jAtY0tGvu8"
   },
   "outputs": [],
   "source": [
    "hell_dict={}\n",
    "\n",
    "for i in range(len(sorted_first_path)):\n",
    "    hell_dict[sorted_first_path[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oxZTgHBGvu8"
   },
   "outputs": [],
   "source": [
    "tmp_paths=paths.reshape(-1)\n",
    "new_paths=np.empty(tmp_paths.shape)\n",
    "\n",
    "for i in range(len(tmp_paths)):\n",
    "    new_paths[i]=hell_dict[tmp_paths[i]]\n",
    "    \n",
    "paths=new_paths.astype(np.int32).reshape(paths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWmsbqVbGvu8"
   },
   "outputs": [],
   "source": [
    "MATRIX_3d_total=np.zeros((how_many_images,number_of_points,number_of_points))\n",
    "\n",
    "for i in range(0,how_many_images):\n",
    "    ithrow=paths[i]\n",
    "    \n",
    "    for j in range(0,last_column_index-1):\n",
    "        MATRIX_3d_total[i,j,ithrow[j]]=1\n",
    "\n",
    "MATRIX_3d_total_reshaped=MATRIX_3d_total.reshape(how_many_images,1,number_of_points,number_of_points)\n",
    "# Torch에서는 (batch size, channel, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CaAaU19-Gvu9"
   },
   "outputs": [],
   "source": [
    "# We now have MATRIX_3d_total and corresponding label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHblXB2XGvu9"
   },
   "outputs": [],
   "source": [
    "total_indices=np.arange(how_many_images)\n",
    "np.random.shuffle(total_indices)\n",
    "train_indices=total_indices[0:num_train_images]\n",
    "test_indices=total_indices[num_train_images:how_many_images]\n",
    "\n",
    "MATRIX_3d_TRAINING=torch.from_numpy(MATRIX_3d_total_reshaped[train_indices,:,:,:])\n",
    "MATRIX_3d_TESTING=torch.from_numpy(MATRIX_3d_total_reshaped[test_indices,:,:,:])\n",
    "label_TRAINING=torch.from_numpy(Label_total[train_indices])\n",
    "label_TESTING=torch.from_numpy(Label_total[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImdAV4c4Gvu9"
   },
   "outputs": [],
   "source": [
    "# # Debugging\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# label_TESTING[32]\n",
    "# MATRIX_3d_TESTING[32,:,:,0]\n",
    "# paths[test_indices[32]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0kh8JAMGvu9",
    "outputId": "5361ab0a-826f-4ffc-dff5-ef25b785d83c"
   },
   "outputs": [],
   "source": [
    "print(MATRIX_3d_TRAINING.shape)\n",
    "print(MATRIX_3d_TESTING.shape)\n",
    "print(label_TRAINING.shape)\n",
    "print(label_TESTING.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6R8gwJKGvu-"
   },
   "outputs": [],
   "source": [
    "########################## PREPROCESSING DONE ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBJ78oleGvu-"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):  # Torch에서는 (batch size, channel, height, width)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64,128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(math.floor(number_of_points/8)*math.floor(number_of_points/8)*128, 800)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(800, 2, bias =True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACOzUI_QGvu-"
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(number_of_points*number_of_points,800,bias=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(800,2,bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = x.view(x.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMX3OIxVGvu_"
   },
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Linear, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(number_of_points*number_of_points,2,bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = x.view(x.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02deapuzGvu_"
   },
   "outputs": [],
   "source": [
    "if ML_model=='CNN':\n",
    "    model = CNN().to(device)\n",
    "elif ML_model=='NN':\n",
    "    model = NN().to(device)\n",
    "elif ML_model=='Linear':\n",
    "    model = Linear().to(device)\n",
    "else:\n",
    "    raise NameError('Select proper ML model!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jvhcpGPzGvu_",
    "outputId": "063cc38a-fc0b-4e9b-90fe-0f4bfd7982c5"
   },
   "outputs": [],
   "source": [
    "value = (torch.Tensor(1,1,number_of_points,number_of_points)).to(device)\n",
    "print( (model(value)).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LLyg9hRGvvE"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71QEMc4EGvvE"
   },
   "outputs": [],
   "source": [
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcUEE8OZGvvF",
    "outputId": "f6f573e6-8610-4ac8-ce69-5b8e81737047",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training\n",
    " \n",
    "remainder=np.arange(num_train_images)\n",
    "total_batch = int(num_train_images/batch_size)\n",
    "epoch=0\n",
    " \n",
    "print('Learning Started!')\n",
    " \n",
    "training_start_time=time.time()\n",
    " \n",
    "while 1:\n",
    "    avg_cost = 0\n",
    "    \n",
    "    np.random.shuffle(remainder)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        current_batch_indices=remainder[i*batch_size:(i+1)*batch_size]\n",
    "        \n",
    "        batch_xs = (MATRIX_3d_TRAINING[current_batch_indices,:,:,:]).to(device=device, dtype=torch.float)\n",
    "        batch_ys = (label_TRAINING[current_batch_indices]).to(device=device, dtype=torch.int64)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(batch_xs)\n",
    "        \n",
    "        cost = criterion(hypothesis, batch_ys)\n",
    "        cost.backward()\n",
    "        optimizer.step()        \n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))\n",
    "    loss_tracker(loss_plt, torch.Tensor([avg_cost]), torch.Tensor([epoch]))\n",
    "        \n",
    "    epoch=epoch+1\n",
    "    \n",
    "    if epoch == how_many_epochs:\n",
    "        break\n",
    " \n",
    "training_end_time=time.time()\n",
    "print('Learning Finished!')\n",
    "print('Elapsed time: {}(s)'.format(training_end_time-training_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5O_yBUKGvvF"
   },
   "outputs": [],
   "source": [
    "########################## POSTPROCESSING ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IW6PSDG0GvvG",
    "outputId": "3bf0ff7d-7dd2-4dfa-a5ba-8185d7c7bd0f"
   },
   "outputs": [],
   "source": [
    "prediction_start_time=time.time()\n",
    " \n",
    "all_the_matrices=torch.from_numpy(MATRIX_3d_total_reshaped).to(device=device, dtype=torch.float) \n",
    " \n",
    "with torch.no_grad():\n",
    "    prediction = model(all_the_matrices)\n",
    "    PROBS_GOOD_tensor=F.softmax(prediction, dim=1)[:,1]\n",
    "    \n",
    "PROBS_GOOD=PROBS_GOOD_tensor.numpy()\n",
    "predicted_ranking=np.argsort(-PROBS_GOOD, kind='mergesort').astype(np.int32) # from the best one to the worst one\n",
    " \n",
    "prediction_end_time=time.time()\n",
    " \n",
    "print(prediction_end_time-prediction_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bG6aBVwjGvvG"
   },
   "outputs": [],
   "source": [
    "df_ranking = pd.DataFrame(predicted_ranking)\n",
    "filepath = 'RANKING_' + ML_model + '_' + str(num_train_images) + '_' + str(how_many_epochs) + '.xlsx'\n",
    "\n",
    "df_ranking.to_excel(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpbNCFfdGvvH"
   },
   "outputs": [],
   "source": [
    "########################## DRAWING ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwcchZvOGvvH"
   },
   "outputs": [],
   "source": [
    "excel_to_read = 'RANKING_' + ML_model + '_' + str(num_train_images) + '_' + str(how_many_epochs) + '.xlsx'\n",
    "\n",
    "\n",
    "df_ranking=pd.read_excel(excel_to_read, sheet_name='Sheet1')  # for robustness\n",
    "actual_rank=np.arange(df_np.shape[0]).astype(np.int32)\n",
    "\n",
    "big_bro=df_ranking.T.values[0] # predicted ranking (same as 'predicted_ranking' just above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jmePqWjfGvvH",
    "outputId": "329c50b7-9e3d-4446-8661-9a549aa3f4f5"
   },
   "outputs": [],
   "source": [
    "t0=time.time()\n",
    "\n",
    "big_bro_list=list(big_bro)\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "predicted_rank_4_train_indices=[big_bro_list.index(k) for k in train_indices]\n",
    "predicted_rank_4_test_indices=[big_bro_list.index(k) for k in test_indices]\n",
    "\n",
    "t2=time.time()\n",
    "\n",
    "print(t1-t0)\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfCh_zl7GvvH",
    "outputId": "c9316bdd-38b3-467d-a617-4e8ceb9eca36"
   },
   "outputs": [],
   "source": [
    "# All data\n",
    "\n",
    "figure(num=None, figsize=(8, 6), dpi=200, facecolor='w', edgecolor='k')\n",
    "\n",
    "if len(train_indices) < len(test_indices):\n",
    "    plt.scatter(predicted_rank_4_test_indices, test_indices, c='blue', s=0.4, label='Test data (blue)')\n",
    "    plt.scatter(predicted_rank_4_train_indices, train_indices, c='gray', s=0.4, label='Training data (gray)')\n",
    "\n",
    "else:\n",
    "    plt.scatter(predicted_rank_4_train_indices, train_indices, c='gray', s=0.4, label='Training data (gray)')\n",
    "    plt.scatter(predicted_rank_4_test_indices, test_indices, c='blue', s=0.4, label='Test data (blue)')\n",
    "\n",
    "\n",
    "plt.plot(actual_rank,actual_rank,color='red', linewidth=3, label='Reference line')\n",
    "\n",
    "nice_title = ML_model + ' Model ' + '(' + str(num_train_images) + ' training data)'\n",
    "\n",
    "plt.title(nice_title)\n",
    "plt.xlabel('Predicted rank')\n",
    "plt.ylabel('Actual rank')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlim(0,df_np.shape[0])\n",
    "plt.ylim(0,df_np.shape[0])\n",
    "\n",
    "name = 'RANKING_' + ML_model + '_' + str(num_train_images) + '_' + str(how_many_epochs) + '.eps'\n",
    "\n",
    "plt.savefig(name, dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mi1CoTWiGvvI",
    "outputId": "003d7a04-b6d4-43fa-9651-59c28e1dbb8b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Top 100\n",
    "\n",
    "figure(num=None, figsize=(8, 6), dpi=200, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.scatter(predicted_rank_4_train_indices, train_indices, c='gray', s=18, label='Training data (gray)')\n",
    "plt.scatter(predicted_rank_4_test_indices, test_indices, c='blue', s=18, label='Test data (blue)')\n",
    "\n",
    "plt.plot(actual_rank[0:100],actual_rank[0:100],color='red', linewidth=1, label='Reference line')\n",
    "\n",
    "nice_title2 = ML_model + ' Model ' + '(' + str(num_train_images) + ' training data, Closeup)'\n",
    "plt.title(nice_title2)\n",
    "plt.xlabel('Predicted rank')\n",
    "plt.ylabel('Actual rank')\n",
    "plt.grid()\n",
    "plt.xlim(0,99)\n",
    "plt.ylim(0,99)\n",
    "plt.legend()\n",
    "\n",
    "name = 'RANKING_TOP100_' + ML_model + '_' + str(num_train_images) + '_' + str(how_many_epochs) + '.eps'\n",
    "\n",
    "plt.savefig(name, dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fACa2cNgGvvI"
   },
   "outputs": [],
   "source": [
    "config=ML_model + '_' + str(num_train_images) + '_' + str(how_many_epochs)\n",
    "\n",
    "training_time=str(training_end_time-training_start_time)\n",
    "prediction_time=str(prediction_end_time-prediction_start_time)\n",
    "\n",
    "\n",
    "with open(\"time_elapse.txt\",\"a\") as f:\n",
    "    f.write(\"\\n----------\\n\")\n",
    "    f.write(config)\n",
    "    f.write('\\n')\n",
    "    f.write('Training time: ')\n",
    "    f.write('{}(s)'.format(training_time))\n",
    "    f.write('\\n')\n",
    "    f.write('Prediction time: ')\n",
    "    f.write('{}(s)'.format(prediction_time))\n",
    "    f.write('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SE4h_o0sGvvI"
   },
   "outputs": [],
   "source": [
    "if len(train_indices) >= len(test_indices):\n",
    "    file_name='Test_indices_' + ML_model + '_' + str(num_train_images) + '_' + str(how_many_epochs) + '.xlsx'\n",
    "\n",
    "    datt=np.array(predicted_rank_4_test_indices).astype(np.int32)\n",
    "    \n",
    "else:\n",
    "    file_name='Train_indices_' + ML_model + '_' + str(num_train_images) + '_' + str(how_many_epochs) + '.xlsx'\n",
    "\n",
    "\n",
    "    datt=np.array(predicted_rank_4_train_indices).astype(np.int32)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecg7-PcoGvvI"
   },
   "outputs": [],
   "source": [
    "df_ind = pd.DataFrame(datt)\n",
    "df_ind.to_excel(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WuqkweI1GvvI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PHASE2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
